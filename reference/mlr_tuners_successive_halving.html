<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content='TunerSuccessiveHalving class that implements the successive halving
algorithm (SHA). SHA randomly samples n candidate
hyperparameter configurations and allocates a minimum budget (r_min) to all
candidates. The candidates are raced down in stages to a single best
candidate by repeatedly increasing the budget by a factor of eta and
promoting only the best 1 / eta  fraction to the next stage. This means
promising hyperparameter configurations are allocated a higher budget overall
and lower performing ones are discarded early on.
The budget hyperparameter must be tagged with "budget" in the search space.
The minimum budget (r_min) which is allocated in the base stage, is set by
the lower bound of the budget parameter. The upper bound  defines the maximum
budget (r_max) which is allocated to the candidates in the last stage. The
number of stages is computed so that each candidate in base stage is
allocated the minimum budget and the candidates in the last stage are not
evaluated on more than the maximum budget. The following table is the stage
layout for eta = 2, r_min = 1 and r_max = 8.
in_ir_i
081
142
224
318




i is stage number, n_i is the number of configurations and r_i is the
budget allocated to a single configuration.'><title>Hyperparameter Tuning with Successive Halving — mlr_tuners_successive_halving • mlr3hyperband</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><link href="../deps/_Roboto-0.4.1/font.css" rel="stylesheet"><link href="../deps/_JetBrains%20Mono-0.4.1/font.css" rel="stylesheet"><link href="../deps/_Roboto%20Slab-0.4.1/font.css" rel="stylesheet"><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Hyperparameter Tuning with Successive Halving — mlr_tuners_successive_halving"><meta property="og:description" content='TunerSuccessiveHalving class that implements the successive halving
algorithm (SHA). SHA randomly samples n candidate
hyperparameter configurations and allocates a minimum budget (r_min) to all
candidates. The candidates are raced down in stages to a single best
candidate by repeatedly increasing the budget by a factor of eta and
promoting only the best 1 / eta  fraction to the next stage. This means
promising hyperparameter configurations are allocated a higher budget overall
and lower performing ones are discarded early on.
The budget hyperparameter must be tagged with "budget" in the search space.
The minimum budget (r_min) which is allocated in the base stage, is set by
the lower bound of the budget parameter. The upper bound  defines the maximum
budget (r_max) which is allocated to the candidates in the last stage. The
number of stages is computed so that each candidate in base stage is
allocated the minimum budget and the candidates in the last stage are not
evaluated on more than the maximum budget. The following table is the stage
layout for eta = 2, r_min = 1 and r_max = 8.
in_ir_i
081
142
224
318




i is stage number, n_i is the number of configurations and r_i is the
budget allocated to a single configuration.'><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">mlr3hyperband</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.4.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr3book.mlr-org.com">
    <span class="fa fa fa fa-link"></span>
     
    mlr3book
  </a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlr-org/mlr3hyperband/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Hyperparameter Tuning with Successive Halving</h1>
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr3hyperband/blob/HEAD/R/TunerSuccessiveHalving.R" class="external-link"><code>R/TunerSuccessiveHalving.R</code></a></small>
      <div class="d-none name"><code>mlr_tuners_successive_halving.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><code>TunerSuccessiveHalving</code> class that implements the successive halving
algorithm (SHA). SHA randomly samples <code>n</code> candidate
hyperparameter configurations and allocates a minimum budget (<code>r_min</code>) to all
candidates. The candidates are raced down in stages to a single best
candidate by repeatedly increasing the budget by a factor of <code>eta</code> and
promoting only the best <code>1 / eta </code> fraction to the next stage. This means
promising hyperparameter configurations are allocated a higher budget overall
and lower performing ones are discarded early on.</p>
<p>The budget hyperparameter must be tagged with <code>"budget"</code> in the search space.
The minimum budget (<code>r_min</code>) which is allocated in the base stage, is set by
the lower bound of the budget parameter. The upper bound  defines the maximum
budget (<code>r_max</code>) which is allocated to the candidates in the last stage. The
number of stages is computed so that each candidate in base stage is
allocated the minimum budget and the candidates in the last stage are not
evaluated on more than the maximum budget. The following table is the stage
layout for <code>eta = 2</code>, <code>r_min = 1</code> and <code>r_max = 8</code>.</p><table class="table table"><tr><td><code>i</code></td><td><code>n_i</code></td><td><code>r_i</code></td></tr><tr><td>0</td><td>8</td><td>1</td></tr><tr><td>1</td><td>4</td><td>2</td></tr><tr><td>2</td><td>2</td><td>4</td></tr><tr><td>3</td><td>1</td><td>8</td></tr></table><p><code>i</code> is stage number, <code>n_i</code> is the number of configurations and <code>r_i</code> is the
budget allocated to a single configuration.</p>
    </div>


    <div class="section level2">
    <h2 id="source">Source<a class="anchor" aria-label="anchor" href="#source"></a></h2>
    <p>Jamieson K, Talwalkar A (2016).
“Non-stochastic Best Arm Identification and Hyperparameter Optimization.”
In Gretton A, Robert CC (eds.), <em>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</em>, volume 51 series Proceedings of Machine Learning Research, 240-248.
<a href="http://proceedings.mlr.press/v51/jamieson16.html" class="external-link">http://proceedings.mlr.press/v51/jamieson16.html</a>.</p>
    </div>
    <div class="section level2">
    <h2 id="subsample-budget">Subsample Budget<a class="anchor" aria-label="anchor" href="#subsample-budget"></a></h2>
    

<p>If the learner lacks a natural budget parameter,
<a href="https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_subsample.html" class="external-link">mlr3pipelines::PipeOpSubsample</a> can be applied to use the subsampling rate
as budget parameter. The resulting <a href="https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html" class="external-link">mlr3pipelines::GraphLearner</a> is fitted on
small proportions of the <a href="https://mlr3.mlr-org.com/reference/Task.html" class="external-link">mlr3::Task</a> in the first stage, and on the complete
task in last stage.</p>
    </div>
    <div class="section level2">
    <h2 id="parameters">Parameters<a class="anchor" aria-label="anchor" href="#parameters"></a></h2>
    

<dl><dt><code>n</code></dt>
<dd><p><code>integer(1)</code><br>
Number of candidates in base stage.</p></dd>

<dt><code>eta</code></dt>
<dd><p><code>numeric(1)</code><br>
With every stage, the budget is increased by a factor of <code>eta</code>
and only the best <code>1 / eta</code> candidates are promoted to the next stage.
Non-integer values are supported, but <code>eta</code> is not allowed to be less or
equal 1.</p></dd>

<dt><code>sampler</code></dt>
<dd><p><a href="https://paradox.mlr-org.com/reference/Sampler.html" class="external-link">paradox::Sampler</a><br>
Object defining how the samples of the parameter space should be drawn. The
default is uniform sampling.</p></dd>

<dt><code>repeats</code></dt>
<dd><p><code>logical(1)</code><br>
If <code>FALSE</code> (default), SHA terminates once all stages are evaluated.
Otherwise, SHA starts over again once the last stage is evaluated.</p></dd>

<dt><code>adjust_minimum_budget</code></dt>
<dd><p><code>logical(1)</code><br>
If <code>TRUE</code>, minimum budget is increased so that the last stage uses the
maximum budget defined in the search space.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="archive">Archive<a class="anchor" aria-label="anchor" href="#archive"></a></h2>
    

<p>The <a href="https://mlr3tuning.mlr-org.com/reference/ArchiveTuning.html" class="external-link">mlr3tuning::ArchiveTuning</a> holds the following additional columns that
are specific to the successive halving algorithm:</p><ul><li><p><code>stage</code> (<code>integer(1))</code><br>
Stage index. Starts counting at 0.</p></li>
<li><p><code>repetition</code> (<code>integer(1))</code><br>
Repetition index. Start counting at 1.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="custom-sampler">Custom Sampler<a class="anchor" aria-label="anchor" href="#custom-sampler"></a></h2>
    

<p>Hyperband supports custom <a href="https://paradox.mlr-org.com/reference/Sampler.html" class="external-link">paradox::Sampler</a> object for initial
configurations in each bracket.
A custom sampler may look like this (the full example is given in the
<em>examples</em> section):</p><div class="sourceCode"><pre><code><span class="co"># - beta distribution with alpha = 2 and beta = 5</span>
<span class="co"># - categorical distribution with custom probabilities</span>
<span class="va">sampler</span> <span class="op">=</span> <span class="va"><a href="https://paradox.mlr-org.com/reference/SamplerJointIndep.html" class="external-link">SamplerJointIndep</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>
  <span class="va"><a href="https://paradox.mlr-org.com/reference/Sampler1DRfun.html" class="external-link">Sampler1DRfun</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">params</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>, <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">2</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span>,
  <span class="va"><a href="https://paradox.mlr-org.com/reference/Sampler1DCateg.html" class="external-link">Sampler1DCateg</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">params</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span><span class="op">)</span></code></pre></div>

    </div>
    <div class="section level2">
    <h2 id="progress-bars">Progress Bars<a class="anchor" aria-label="anchor" href="#progress-bars"></a></h2>
    

<p><code>$optimize()</code> supports progress bars via the package <a href="https://CRAN.R-project.org/package=progressr" class="external-link"><span class="pkg">progressr</span></a>
combined with a <a href="https://bbotk.mlr-org.com/reference/Terminator.html" class="external-link">Terminator</a>. Simply wrap the function in
<code>progressr::with_progress()</code> to enable them. We recommend to use package
<a href="https://CRAN.R-project.org/package=progress" class="external-link"><span class="pkg">progress</span></a> as backend; enable with <code>progressr::handlers("progress")</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="parallelization">Parallelization<a class="anchor" aria-label="anchor" href="#parallelization"></a></h2>
    

<p>The hyperparameter configurations of one stage are evaluated in parallel with
the <a href="https://CRAN.R-project.org/package=future" class="external-link"><span class="pkg">future</span></a> package. To select a parallel backend, use
<code><a href="https://future.futureverse.org/reference/plan.html" class="external-link">future::plan()</a></code>.</p>
    </div>
    <div class="section level2">
    <h2 id="logging">Logging<a class="anchor" aria-label="anchor" href="#logging"></a></h2>
    

<p>Hyperband uses a logger (as implemented in <a href="https://CRAN.R-project.org/package=lgr" class="external-link"><span class="pkg">lgr</span></a>) from package
<a href="https://CRAN.R-project.org/package=bbotk" class="external-link"><span class="pkg">bbotk</span></a>.
Use <code>lgr::get_logger("bbotk")</code> to access and control the logger.</p>
    </div>
    <div class="section level2">
    <h2 id="super-classes">Super classes<a class="anchor" aria-label="anchor" href="#super-classes"></a></h2>
    <p><code><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html" class="external-link">mlr3tuning::Tuner</a></code> -&gt; <code><a href="https://mlr3tuning.mlr-org.com/reference/TunerFromOptimizer.html" class="external-link">mlr3tuning::TunerFromOptimizer</a></code> -&gt; <code>TunerSuccessiveHalving</code></p>
    </div>
    <div class="section level2">
    <h2 id="methods">Methods<a class="anchor" aria-label="anchor" href="#methods"></a></h2>
    
<div class="section">
<h3 id="public-methods">Public methods<a class="anchor" aria-label="anchor" href="#public-methods"></a></h3>

<ul><li><p><a href="#method-new"><code>TunerSuccessiveHalving$new()</code></a></p></li>
<li><p><a href="#method-clone"><code>TunerSuccessiveHalving$clone()</code></a></p></li>
</ul></div><p><details open><summary>Inherited methods</summary><ul><li><p><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="format"><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html#method-format"><code>mlr3tuning::Tuner$format()</code></a></span></p></li>
<li><p><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="print"><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html#method-print"><code>mlr3tuning::Tuner$print()</code></a></span></p></li>
<li><p><span class="pkg-link" data-pkg="mlr3tuning" data-topic="TunerFromOptimizer" data-id="optimize"><a href="https://mlr3tuning.mlr-org.com/reference/TunerFromOptimizer.html#method-optimize"><code>mlr3tuning::TunerFromOptimizer$optimize()</code></a></span></p></li>
</ul></details></p><hr><a id="method-new"></a><div class="section">
<h3 id="method-new-">Method <code>new()</code><a class="anchor" aria-label="anchor" href="#method-new-"></a></h3>
<p>Creates a new instance of this <a href="https://r6.r-lib.org/reference/R6Class.html" class="external-link">R6</a> class.</p><div class="section">
<h4 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span class="va"><a href="../reference/mlr_tuners_successive_halving.html">TunerSuccessiveHalving</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span></code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-clone"></a><div class="section">
<h3 id="method-clone-">Method <code>clone()</code><a class="anchor" aria-label="anchor" href="#method-clone-"></a></h3>
<p>The objects of this class are cloneable with this method.</p><div class="section">
<h4 id="usage-1">Usage<a class="anchor" aria-label="anchor" href="#usage-1"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span class="va">TunerSuccessiveHalving</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span>deep <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h4>
<p></p><div class="arguments"><dl><dt><code>deep</code></dt>
<dd><p>Whether to make a deep clone.</p></dd>


</dl><p></p></div>
</div>

</div>

    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"xgboost"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span class="r-in">  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3learners.mlr-org.com" class="external-link">mlr3learners</a></span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in">  <span class="co"># define hyperparameter and budget parameter</span></span>
<span class="r-in">  <span class="va">search_space</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html" class="external-link">ps</a></span><span class="op">(</span></span>
<span class="r-in">    nrounds <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html" class="external-link">p_int</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">1</span>, upper <span class="op">=</span> <span class="fl">16</span>, tags <span class="op">=</span> <span class="st">"budget"</span><span class="op">)</span>,</span>
<span class="r-in">    eta <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html" class="external-link">p_dbl</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">0</span>, upper <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span class="r-in">    booster <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html" class="external-link">p_fct</a></span><span class="op">(</span>levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gbtree"</span>, <span class="st">"gblinear"</span>, <span class="st">"dart"</span><span class="op">)</span><span class="op">)</span></span>
<span class="r-in">  <span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in">  <span class="co"># \donttest{</span></span>
<span class="r-in">  <span class="co"># hyperparameter tuning on the pima indians diabetes data set</span></span>
<span class="r-in">  <span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span></span>
<span class="r-in">    method <span class="op">=</span> <span class="st">"successive_halving"</span>,</span>
<span class="r-in">    task <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">tsk</a></span><span class="op">(</span><span class="st">"pima"</span><span class="op">)</span>,</span>
<span class="r-in">    learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">lrn</a></span><span class="op">(</span><span class="st">"classif.xgboost"</span>, eval_metric <span class="op">=</span> <span class="st">"logloss"</span><span class="op">)</span>,</span>
<span class="r-in">    resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span class="r-in">    measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>,</span>
<span class="r-in">    search_space <span class="op">=</span> <span class="va">search_space</span>,</span>
<span class="r-in">    term_evals <span class="op">=</span> <span class="fl">100</span></span>
<span class="r-in">  <span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in">  <span class="co"># best performing hyperparameter configuration</span></span>
<span class="r-in">  <span class="va">instance</span><span class="op">$</span><span class="va">result</span></span>
<span class="r-in">  <span class="co"># }</span></span>
<span class="r-in"><span class="op">}</span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    nrounds       eta booster learner_param_vals  x_domain classif.ce</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1:       4 0.5108574  gbtree          &lt;list[6]&gt; &lt;list[3]&gt;  0.2617188</span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Marc Becker, Sebastian Gruber, Jakob Richter, Julia Moosbauer, Bernd Bischl.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.4.</p>
</div>

    </footer></div>

  

  

  </body></html>

