<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Hyperparameter Tuning with Successive Halving — mlr_tuners_successive_halving • mlr3hyperband</title><!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Roboto-0.4.10/font.css" rel="stylesheet"><link href="../deps/JetBrains_Mono-0.4.10/font.css" rel="stylesheet"><link href="../deps/Roboto_Slab-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Hyperparameter Tuning with Successive Halving — mlr_tuners_successive_halving"><meta name="description" content="Optimizer using the Successive Halving Algorithm (SHA).
SHA is initialized with the number of starting configurations n, the proportion of configurations discarded in each stage eta, and the minimum r_min and maximum _max budget of a single evaluation.
The algorithm starts by sampling n random configurations and allocating the minimum budget r_min to them.
The configurations are evaluated and 1 / eta of the worst-performing configurations are discarded.
The remaining configurations are promoted to the next stage and evaluated on a larger budget.
The following table is the stage layout for eta = 2, r_min = 1 and r_max = 8.
in_ir_i
081
142
224
318




i is the stage number, n_i is the number of configurations and r_i is the budget allocated to a single configuration.
The number of stages is calculated so that each stage consumes approximately the same budget.
This sometimes results in the minimum budget having to be slightly adjusted by the algorithm."><meta property="og:description" content="Optimizer using the Successive Halving Algorithm (SHA).
SHA is initialized with the number of starting configurations n, the proportion of configurations discarded in each stage eta, and the minimum r_min and maximum _max budget of a single evaluation.
The algorithm starts by sampling n random configurations and allocating the minimum budget r_min to them.
The configurations are evaluated and 1 / eta of the worst-performing configurations are discarded.
The remaining configurations are promoted to the next stage and evaluated on a larger budget.
The following table is the stage layout for eta = 2, r_min = 1 and r_max = 8.
in_ir_i
081
142
224
318




i is the stage number, n_i is the number of configurations and r_i is the budget allocated to a single configuration.
The number of stages is calculated so that each stage consumes approximately the same budget.
This sometimes results in the minimum budget having to be slightly adjusted by the algorithm."><meta property="og:image" content="https://mlr3hyperband.mlr-org.com/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">mlr3hyperband</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-alt"></span> Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mlr3book.mlr-org.com"><span class="fa fa-link"></span> mlr3book</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlr-org/mlr3hyperband/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/"><span class="fa fa-comments"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr"><span class="fa fab fa-stack-overflow"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mlr-org.com/"><span class="fa fa-rss"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Hyperparameter Tuning with Successive Halving</h1>
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr3hyperband/blob/main/R/TunerBatchSuccessiveHalving.R" class="external-link"><code>R/TunerBatchSuccessiveHalving.R</code></a></small>
      <div class="d-none name"><code>mlr_tuners_successive_halving.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Optimizer using the Successive Halving Algorithm (SHA).
SHA is initialized with the number of starting configurations <code>n</code>, the proportion of configurations discarded in each stage <code>eta</code>, and the minimum <code>r_min</code> and maximum <code>_max</code> budget of a single evaluation.
The algorithm starts by sampling <code>n</code> random configurations and allocating the minimum budget <code>r_min</code> to them.
The configurations are evaluated and <code>1 / eta</code> of the worst-performing configurations are discarded.
The remaining configurations are promoted to the next stage and evaluated on a larger budget.
The following table is the stage layout for <code>eta = 2</code>, <code>r_min = 1</code> and <code>r_max = 8</code>.</p><table class="table table"><tr><td><code>i</code></td><td><code>n_i</code></td><td><code>r_i</code></td></tr><tr><td>0</td><td>8</td><td>1</td></tr><tr><td>1</td><td>4</td><td>2</td></tr><tr><td>2</td><td>2</td><td>4</td></tr><tr><td>3</td><td>1</td><td>8</td></tr></table><p><code>i</code> is the stage number, <code>n_i</code> is the number of configurations and <code>r_i</code> is the budget allocated to a single configuration.</p>
<p>The number of stages is calculated so that each stage consumes approximately the same budget.
This sometimes results in the minimum budget having to be slightly adjusted by the algorithm.</p>
    </div>


    <div class="section level2">
    <h2 id="source">Source<a class="anchor" aria-label="anchor" href="#source"></a></h2>
    <p>Jamieson K, Talwalkar A (2016).
“Non-stochastic Best Arm Identification and Hyperparameter Optimization.”
In Gretton A, Robert CC (eds.), <em>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</em>, volume 51 series Proceedings of Machine Learning Research, 240-248.
<a href="http://proceedings.mlr.press/v51/jamieson16.html" class="external-link">http://proceedings.mlr.press/v51/jamieson16.html</a>.</p>
    </div>
    <div class="section level2">
    <h2 id="dictionary">Dictionary<a class="anchor" aria-label="anchor" href="#dictionary"></a></h2>


<p>This <a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html" class="external-link">mlr3tuning::Tuner</a> can be instantiated via the <a href="https://mlr3misc.mlr-org.com/reference/Dictionary.html" class="external-link">dictionary</a>
<a href="https://mlr3tuning.mlr-org.com/reference/mlr_tuners.html" class="external-link">mlr3tuning::mlr_tuners</a> or with the associated sugar function <code><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html" class="external-link">mlr3tuning::tnr()</a></code>:</p>
<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>TunerBatchSuccessiveHalving<span class="sc">$</span><span class="fu">new</span>()</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>mlr_tuners<span class="sc">$</span><span class="fu">get</span>(<span class="st">"successive_halving"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">tnr</span>(<span class="st">"successive_halving"</span>)</span></code></pre><p></p></div>
    </div>
    <div class="section level2">
    <h2 id="subsample-budget">Subsample Budget<a class="anchor" aria-label="anchor" href="#subsample-budget"></a></h2>


<p>If the learner lacks a natural budget parameter,
<a href="https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_subsample.html" class="external-link">mlr3pipelines::PipeOpSubsample</a> can be applied to use the subsampling rate
as budget parameter. The resulting <a href="https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html" class="external-link">mlr3pipelines::GraphLearner</a> is fitted on
small proportions of the <a href="https://mlr3.mlr-org.com/reference/Task.html" class="external-link">mlr3::Task</a> in the first stage, and on the complete
task in last stage.</p>
    </div>
    <div class="section level2">
    <h2 id="custom-sampler">Custom Sampler<a class="anchor" aria-label="anchor" href="#custom-sampler"></a></h2>


<p>Hyperband supports custom <a href="https://paradox.mlr-org.com/reference/Sampler.html" class="external-link">paradox::Sampler</a> object for initial
configurations in each bracket.
A custom sampler may look like this (the full example is given in the
<em>examples</em> section):</p>
<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># - beta distribution with alpha = 2 and beta = 5</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># - categorical distribution with custom probabilities</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>sampler <span class="ot">=</span> SamplerJointIndep<span class="sc">$</span><span class="fu">new</span>(<span class="fu">list</span>(</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>  Sampler1DRfun<span class="sc">$</span><span class="fu">new</span>(params[[<span class="dv">2</span>]], <span class="cf">function</span>(n) <span class="fu">rbeta</span>(n, <span class="dv">2</span>, <span class="dv">5</span>)),</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>  Sampler1DCateg<span class="sc">$</span><span class="fu">new</span>(params[[<span class="dv">3</span>]], <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>))</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>))</span></code></pre><p></p></div>
    </div>
    <div class="section level2">
    <h2 id="progress-bars">Progress Bars<a class="anchor" aria-label="anchor" href="#progress-bars"></a></h2>


<p><code>$optimize()</code> supports progress bars via the package <a href="https://CRAN.R-project.org/package=progressr" class="external-link"><span class="pkg">progressr</span></a>
combined with a <a href="https://bbotk.mlr-org.com/reference/Terminator.html" class="external-link">bbotk::Terminator</a>. Simply wrap the function in
<code>progressr::with_progress()</code> to enable them. We recommend to use package
<a href="https://CRAN.R-project.org/package=progress" class="external-link"><span class="pkg">progress</span></a> as backend; enable with <code>progressr::handlers("progress")</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="parallelization">Parallelization<a class="anchor" aria-label="anchor" href="#parallelization"></a></h2>


<p>The hyperparameter configurations of one stage are evaluated in parallel with the <a href="https://CRAN.R-project.org/package=future" class="external-link"><span class="pkg">future</span></a> package.
To select a parallel backend, use the <code>plan()</code> function of the <a href="https://CRAN.R-project.org/package=future" class="external-link"><span class="pkg">future</span></a> package.</p>
    </div>
    <div class="section level2">
    <h2 id="logging">Logging<a class="anchor" aria-label="anchor" href="#logging"></a></h2>


<p>Hyperband uses a logger (as implemented in <a href="https://CRAN.R-project.org/package=lgr" class="external-link"><span class="pkg">lgr</span></a>) from package
<a href="https://CRAN.R-project.org/package=bbotk" class="external-link"><span class="pkg">bbotk</span></a>.
Use <code>lgr::get_logger("bbotk")</code> to access and control the logger.</p>
    </div>
    <div class="section level2">
    <h2 id="resources">Resources<a class="anchor" aria-label="anchor" href="#resources"></a></h2>


<p>The <a href="https://mlr-org.com/gallery-all-optimization.html" class="external-link">gallery</a> features a collection of case studies and demos about optimization.</p><ul><li><p><a href="https://mlr-org.com/gallery/series/2023-01-15-hyperband-xgboost/" class="external-link">Tune</a> the hyperparameters of XGBoost with Hyperband (Hyperband can be easily swapped with SHA).</p></li>
<li><p>Use data <a href="https://mlr-org.com/gallery/series/2023-01-16-hyperband-subsampling/" class="external-link">subsampling</a> and Hyperband to optimize a support vector machine.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="parameters">Parameters<a class="anchor" aria-label="anchor" href="#parameters"></a></h2>


<dl><dt><code>n</code></dt>
<dd><p><code>integer(1)</code><br>
Number of configurations in the base stage.</p></dd>

<dt><code>eta</code></dt>
<dd><p><code>numeric(1)</code><br>
With every stage, the budget is increased by a factor of <code>eta</code> and only the best <code>1 / eta</code> configurations are promoted to the next stage.
Non-integer values are supported, but <code>eta</code> is not allowed to be less or equal to 1.</p></dd>

<dt><code>sampler</code></dt>
<dd><p><a href="https://paradox.mlr-org.com/reference/Sampler.html" class="external-link">paradox::Sampler</a><br>
Object defining how the samples of the parameter space should be drawn.
The default is uniform sampling.</p></dd>

<dt><code>repetitions</code></dt>
<dd><p><code>integer(1)</code><br>
If <code>1</code> (default), optimization is stopped once all stages are evaluated.
Otherwise, optimization is stopped after <code>repetitions</code> runs of SHA.
The <a href="https://bbotk.mlr-org.com/reference/Terminator.html" class="external-link">bbotk::Terminator</a> might stop the optimization before all repetitions are executed.</p></dd>

<dt><code>adjust_minimum_budget</code></dt>
<dd><p><code>logical(1)</code><br>
If <code>TRUE</code>, the minimum budget is increased so that the last stage uses the maximum budget defined in the search space.</p></dd>


</dl></div>
    <div class="section level2">
    <h2 id="archive">Archive<a class="anchor" aria-label="anchor" href="#archive"></a></h2>


<p>The <a href="https://bbotk.mlr-org.com/reference/Archive.html" class="external-link">bbotk::Archive</a> holds the following additional columns that are specific to SHA:</p><ul><li><p><code>stage</code> (<code>integer(1))</code><br>
Stage index. Starts counting at 0.</p></li>
<li><p><code>repetition</code> (<code>integer(1))</code><br>
Repetition index. Start counting at 1.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="super-classes">Super classes<a class="anchor" aria-label="anchor" href="#super-classes"></a></h2>
    <p><code><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html" class="external-link">mlr3tuning::Tuner</a></code> -&gt; <code><a href="https://mlr3tuning.mlr-org.com/reference/TunerBatch.html" class="external-link">mlr3tuning::TunerBatch</a></code> -&gt; <code><a href="https://mlr3tuning.mlr-org.com/reference/TunerBatchFromOptimizerBatch.html" class="external-link">mlr3tuning::TunerBatchFromOptimizerBatch</a></code> -&gt; <code>TunerBatchSuccessiveHalving</code></p>
    </div>
    <div class="section level2">
    <h2 id="methods">Methods<a class="anchor" aria-label="anchor" href="#methods"></a></h2>

<div class="section">
<h3 id="public-methods">Public methods<a class="anchor" aria-label="anchor" href="#public-methods"></a></h3>

<ul><li><p><a href="#method-TunerBatchSuccessiveHalving-new"><code>TunerBatchSuccessiveHalving$new()</code></a></p></li>
<li><p><a href="#method-TunerBatchSuccessiveHalving-clone"><code>TunerBatchSuccessiveHalving$clone()</code></a></p></li>
</ul></div><p><details open><summary>Inherited methods</summary><ul><li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="format"><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html#method-format"><code>mlr3tuning::Tuner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="help"><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html#method-help"><code>mlr3tuning::Tuner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="print"><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html#method-print"><code>mlr3tuning::Tuner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="TunerBatchFromOptimizerBatch" data-id="optimize"><a href="https://mlr3tuning.mlr-org.com/reference/TunerBatchFromOptimizerBatch.html#method-optimize"><code>mlr3tuning::TunerBatchFromOptimizerBatch$optimize()</code></a></span></li>
</ul></details></p><hr><a id="method-TunerBatchSuccessiveHalving-new"></a><div class="section">
<h3 id="method-new-">Method <code>new()</code><a class="anchor" aria-label="anchor" href="#method-new-"></a></h3>
<p>Creates a new instance of this <a href="https://r6.r-lib.org/reference/R6Class.html" class="external-link">R6</a> class.</p><div class="section">
<h4 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va"><a href="../reference/mlr_tuners_successive_halving.html">TunerBatchSuccessiveHalving</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-TunerBatchSuccessiveHalving-clone"></a><div class="section">
<h3 id="method-clone-">Method <code>clone()</code><a class="anchor" aria-label="anchor" href="#method-clone-"></a></h3>
<p>The objects of this class are cloneable with this method.</p><div class="section">
<h4 id="usage-1">Usage<a class="anchor" aria-label="anchor" href="#usage-1"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">TunerBatchSuccessiveHalving</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span>deep <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h4>
<p></p><div class="arguments"><dl><dt><code>deep</code></dt>
<dd><p>Whether to make a deep clone.</p></dd>


</dl><p></p></div>
</div>

</div>

    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"xgboost"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3learners.mlr-org.com" class="external-link">mlr3learners</a></span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># define hyperparameter and budget parameter</span></span></span>
<span class="r-in"><span>  <span class="va">search_space</span> <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/ps.html" class="external-link">ps</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>    nrounds <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html" class="external-link">p_int</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">1</span>, upper <span class="op">=</span> <span class="fl">16</span>, tags <span class="op">=</span> <span class="st">"budget"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    eta <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html" class="external-link">p_dbl</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">0</span>, upper <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    booster <span class="op">=</span> <span class="fu"><a href="https://paradox.mlr-org.com/reference/Domain.html" class="external-link">p_fct</a></span><span class="op">(</span>levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gbtree"</span>, <span class="st">"gblinear"</span>, <span class="st">"dart"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># \donttest{</span></span></span>
<span class="r-in"><span>  <span class="co"># hyperparameter tuning on the pima indians diabetes data set</span></span></span>
<span class="r-in"><span>  <span class="va">instance</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html" class="external-link">tnr</a></span><span class="op">(</span><span class="st">"successive_halving"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    task <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">tsk</a></span><span class="op">(</span><span class="st">"pima"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">lrn</a></span><span class="op">(</span><span class="st">"classif.xgboost"</span>, eval_metric <span class="op">=</span> <span class="st">"logloss"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    resampling <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    measures <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    search_space <span class="op">=</span> <span class="va">search_space</span>,</span></span>
<span class="r-in"><span>    term_evals <span class="op">=</span> <span class="fl">100</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># best performing hyperparameter configuration</span></span></span>
<span class="r-in"><span>  <span class="va">instance</span><span class="op">$</span><span class="va">result</span></span></span>
<span class="r-in"><span>  <span class="co"># }</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    nrounds       eta booster learner_param_vals  x_domain classif.ce</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>      &lt;num&gt;     &lt;num&gt;  &lt;char&gt;             &lt;list&gt;    &lt;list&gt;      &lt;num&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1:      16 0.2263371  gbtree          &lt;list[6]&gt; &lt;list[3]&gt;  0.2486979</span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Marc Becker, Sebastian Gruber, Jakob Richter, Julia Moosbauer, Bernd Bischl.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

